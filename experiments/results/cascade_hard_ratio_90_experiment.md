# CASCADE実験結果: HARD_RATIO=0.9

## 実験概要

**日時**: 2025-12-17 09:21:43
**目的**: SmolLM2-135MベースのCASCADE段階的訓練の初回実験

## 設定

| パラメータ | 値 |
|-----------|-----|
| ベースモデル | HuggingFaceTB/SmolLM2-135M-Instruct |
| 段階あたりのレイヤー数 | 8 |
| Hard token比率 | 90.0% |
| 段階数 | 5 |
| エポック数 | 10 |
| バッチサイズ | 32 |
| 学習率 | 0.0001 |
| Early stopping patience | 1 |
| 訓練サンプル数 | 1000 |
| 検証サンプル数 | 100 |
| デバイス | cuda (Colab T4 GPU) |

## ベースモデル情報

- パラメータ数: 134,515,008 (134.5M)
- レイヤー数: 30
- 訓練トークン数: 128,000
- 検証トークン数: 12,800

## 結果

### Stage 1

| 項目 | 値 |
|------|-----|
| 閾値 (cos_sim) | 0.1786 |
| 訓練Hard tokens | 115,200 / 128,000 (90.0%) |
| 検証Hard tokens | 11,520 |
| 追加パラメータ | 56,632,896 (56.6M) |

**訓練ログ**:
```
Epoch 1/10: train_loss=5.1721, val_loss=4.7186, val_ppl=112.01, time=192.7s
Epoch 2/10: train_loss=3.1900, val_loss=4.4359, val_ppl=84.43, time=192.6s
Epoch 3/10: train_loss=2.0465, val_loss=4.4788, val_ppl=88.13, time=192.8s
Early stopping at epoch 3 (patience=1)
```

**最良val_ppl**: 84.43 (Epoch 2)
**訓練時間**: 578.2秒

### Stage 2

| 項目 | 値 |
|------|-----|
| 閾値 (cos_sim) | 0.4670 |
| 訓練Hard tokens | 103,680 / 115,200 (90.0%) |
| 検証Hard tokens | 10,368 |
| 追加パラメータ | 56,632,896 (56.6M) |

**訓練ログ**:
```
Epoch 1/10: train_loss=3.8237, val_loss=4.5288, val_ppl=92.65, time=174.0s
Epoch 2/10: train_loss=1.8745, val_loss=4.5792, val_ppl=97.44, time=173.5s
Early stopping at epoch 2 (patience=1)
```

**最良val_ppl**: 92.65 (Epoch 1)
**訓練時間**: 347.5秒

### Stage 3 (中断)

| 項目 | 値 |
|------|-----|
| 閾値 (cos_sim) | 0.5187 |
| 訓練Hard tokens | 93,312 / 103,680 (90.0%) |
| 検証Hard tokens | 9,331 |
| 追加パラメータ | 56,632,896 (56.6M) |

**訓練ログ** (1エポックで中断):
```
Epoch 1/10: train_loss=2.7556, val_loss=4.5692, val_ppl=96.47, time=156.3s
```

## 分析

### 過学習の兆候

**明確に過学習が発生**:

| Stage | train_loss変化 | val_loss変化 | 診断 |
|-------|---------------|-------------|------|
| 1 | 5.17 → 2.05 (大幅減少) | 4.72 → 4.48 (微減) | 軽度過学習 |
| 2 | 3.82 → 1.87 (大幅減少) | 4.53 → 4.58 (悪化) | 明確な過学習 |

### 閾値の推移

```
Stage 1: 0.1786 (低い = ほぼ全トークンがhard)
Stage 2: 0.4670 (上昇)
Stage 3: 0.5187 (さらに上昇)
```

後段になるほどcos_simが高くなる = hidden statesの変化が小さくなる傾向

### val_pplの推移

```
Stage 1: 84.43 (最良)
Stage 2: 92.65 → 97.44 (悪化)
Stage 3: 96.47 (Epoch 1時点)
```

**Stage 2以降でval_pplが悪化** = 追加したLLMが逆効果の可能性

## 問題点

1. **HARD_RATIO=0.9は高すぎる**: 90%のトークンを「難しい」とするのは、ほぼ全データを使っているのと同じ
2. **過学習**: train_lossは急速に下がるが、val_lossは停滞/悪化
3. **後段LLMの効果が不明確**: val_pplが改善せず悪化

## 次のアクション

**HARD_RATIO=0.6に変更して再実験**

期待される効果:
- より選択的なhard token抽出
- 過学習の軽減
- 各LLMの専門化促進

## パラメータ累計

| Stage | 累計パラメータ数 |
|-------|----------------|
| Base | 134.5M |
| Stage 1 | 134.5M + 56.6M = 191.1M |
| Stage 2 | 191.1M + 56.6M = 247.7M |
| Stage 3 | 247.7M + 56.6M = 304.3M |
